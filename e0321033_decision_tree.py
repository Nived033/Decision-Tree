# -*- coding: utf-8 -*-
"""E0321033_Decision_tree.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VYgV77rtemx3GSBa-3VDT2IMLwAshEQg
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score

# Load the data
data = pd.read_csv('Bank_Stock_Price_10Y.csv')

data.describe()

# Preprocessing: Check for null values and handle them
data.isnull().sum()
data = data.dropna()

# Preprocessing: Normalize the data if it is out of range
scaler = StandardScaler()
data[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']] = scaler.fit_transform(data[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']])

# Preparation: Split the dataset into input and output
X = data.drop('Close', axis=1)
X = X.drop('Date', axis=1)
y = data['Close']

# Preparation: Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the model
model = DecisionTreeRegressor(random_state=42)
model.fit(X_train, y_train)

# Predict the test data set values using the model above
y_pred = model.predict(X_test)

# Calculate the accuracy of the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print('Mean Squared Error:', mse)
print('R-squared:', r2)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

# Load the data
data = pd.read_csv('/content/Bank_Stock_Price_10Y.csv')

# Convert the 'Date' column to Unix timestamps
data['Date'] = pd.to_datetime(data['Date']).astype(int)/10**9

# Split the data into features (X) and target (y)
X = data.drop(['Close'], axis=1)
y = data['Close']

# Define the number of models to train and the number of rows to select for each model
num_models = 10
num_rows_per_model = 50

# Initialize lists to store the model parameters, accuracy, and evaluation metrics
model_params = []
model_accuracies = []
model_metrics = []

# Train the models
for i in range(num_models):
    # Select a random subset of rows from the data with replacement
    random_rows = np.random.choice(len(X), num_rows_per_model, replace=True)
    X_train, X_test, y_train, y_test = train_test_split(X.iloc[random_rows], y.iloc[random_rows], test_size=0.2, random_state=i)

    # Train the decision tree model
    model = DecisionTreeRegressor(random_state=i)
    model.fit(X_train, y_train)

    # Make predictions on the test set
    y_pred = model.predict(X_test)

    # Calculate the accuracy and evaluation metrics
    accuracy = r2_score(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)

    # Save the model parameters, accuracy, and evaluation metrics
    model_params.append(model.get_params())
    model_accuracies.append(accuracy)
    model_metrics.append({'MSE': mse})

    # Print the output of the current decision tree model
    print(f'Model {i+1}:')
    print(f'Accuracy: {accuracy}')
    print(f'MSE: {mse}')
    print('-----------------------------')

